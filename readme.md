# ğŸ§  Tarea 2: PerceptrÃ³n Multicapa (MLP) ğŸš€

Â¡Bienvenido! Este proyecto es una implementaciÃ³n completa de una **Red Neuronal de PerceptrÃ³n Multicapa (MLP)**, construida desde cero en Python, cumpliendo con todos los requisitos de la "Tarea 2".

El proyecto no utiliza librerÃ­as de Deep Learning como PyTorch o TensorFlow, sino que implementa la lÃ³gica de `feedforward` y `backpropagation` manualmente usando **Numpy**.

AdemÃ¡s, incluye una **interfaz grÃ¡fica de usuario (GUI)** ğŸ–¥ï¸ desarrollada con `CustomTkinter` que te permite crear, entrenar, guardar, cargar y probar tus redes neuronales de forma interactiva.

---

## âœ¨ CaracterÃ­sticas Principales

Este proyecto cumple con todos los requisitos funcionales de la tarea:

* **CreaciÃ³n y Carga:** El programa inicia permitiÃ©ndote **crear un nuevo MLP** o **cargar un modelo entrenado** desde un archivo `.json`.
* **Arquitectura Flexible:** ğŸ—ï¸ Al crear una red, puedes especificar su arquitectura completa:
    * Neuronas de entrada
    * Neuronas de salida
    * NÃºmero de capas ocultas
    * NÃºmero de neuronas por cada capa oculta
* **Entrenamiento con Backpropagation:** ğŸš‚ El nÃºcleo del proyecto. La red se entrena usando el algoritmo de retropropagaciÃ³n del error.
* **FunciÃ³n de ActivaciÃ³n ReLU:** Utiliza la funciÃ³n **Rectified Linear Unit (ReLU)** en las capas ocultas para un entrenamiento mÃ¡s rÃ¡pido y eficiente.
* **MonitorizaciÃ³n en Vivo:** ğŸ“ˆ Durante el entrenamiento, el programa **imprime la precisiÃ³n promedio** tanto con los datos de *entrenamiento* como con los de *prueba* al final de **cada Ã©poca**.
* **GestiÃ³n del Modelo:** Una vez que la red estÃ¡ entrenada o cargada, tienes un panel de control con 3 opciones:
    1.  **Ejecutar Feedforward:** âš¡ Prueba la red cargando un archivo `.csv` de prueba.
    2.  **Seguir Entrenando:** ğŸ”„ ContinÃºa el entrenamiento con mÃ¡s Ã©pocas o nuevos archivos.
    3.  **Guardar la Red:** ğŸ’¾ Almacena la arquitectura, pesos y sesgos de tu red en un archivo `.json`.
* **Lector de CSV:** Incluye un lector (`utils.py`) que procesa los archivos `.csv` donde las primeras `N-1` columnas son las entradas y la Ãºltima columna es la salida esperada.

---

## ğŸ”¬ Curiosidades del Proyecto y Conceptos Clave

Este proyecto es una excelente forma de entender los pilares del Deep Learning.

### 1. Â¿Por quÃ© ReLU (Rectified Linear Unit)? âš¡
Como se implementa en `perceptron.py`, ReLU (`f(x) = max(0, x)`) es la funciÃ³n de activaciÃ³n preferida en las capas ocultas sobre opciones mÃ¡s antiguas (como la sigmoide).
* **Evita el "Desvanecimiento del Gradiente":** No se "satura" para valores positivos, permitiendo que el gradiente fluya mejor durante el backpropagation, lo que acelera radicalmente el aprendizaje.
* **Eficiencia Computacional:** Es una operaciÃ³n increÃ­blemente simple y rÃ¡pida (una simple comparaciÃ³n).

### 2. El Motor del Aprendizaje: Backpropagation ğŸ§ âš™ï¸
Implementado en `perceptron.py`, este es el algoritmo que permite a la red "aprender". Funciona calculando el error en la capa de salida y luego propagando ese error "hacia atrÃ¡s", capa por capa, para determinar cuÃ¡nto debe ajustarse cada peso y sesgo en la red para minimizar el error.

### 3. Â¡Hecho desde Cero!
Cumpliendo con un requisito tÃ©cnico clave, este proyecto **no usa PyTorch ni TensorFlow**. Toda la lÃ³gica de matrices, derivadas, propagaciÃ³n y actualizaciÃ³n de pesos estÃ¡ hecha "a mano" con **Numpy**, lo que te obliga a entender *realmente* cÃ³mo funciona una red neuronal por dentro.

---

## ğŸ› ï¸ TecnologÃ­as y Dependencias

Este proyecto estÃ¡ construido 100% en Python y utiliza las siguientes librerÃ­as:

* **Numpy:** Para todos los cÃ¡lculos matriciales y operaciones de la red neuronal.
* **CustomTkinter:** Para la interfaz grÃ¡fica de usuario moderna y atractiva.
* **Matplotlib:** Para la visualizaciÃ³n de la arquitectura de la red.

---

## ğŸš€ Flujo de Trabajo BÃ¡sico:

1.  Al iniciar, elige **"Crear un nuevo perceptrÃ³n"**.
2.  Rellena el formulario con la arquitectura (ej: 2 entradas, 1 salida, 2 capas ocultas con 4 y 3 neuronas).
3.  SerÃ¡s llevado al panel principal. Haz clic en **"Entrenar Red"**.
4.  Se te pedirÃ¡ que definas las Ã©pocas, la tasa de aprendizaje y la tolerancia.
5.  Carga tu archivo `.csv` de **entrenamiento** (ej: `2-d_2-class_train.csv`).
6.  Carga tu archivo `.csv` de **prueba** (ej: `2-d_2-class_test.csv`).
7.  Observa la consola: verÃ¡s la precisiÃ³n de entrenamiento y prueba mejorar con cada Ã©poca ğŸ“ˆ.
8.  Una vez entrenada, puedes usar **"Feedforward"** con un archivo de prueba o **"Guardar red"** para obtener tu archivo `.json`.

---

## ğŸ“‚ Estructura de Archivos
â”œâ”€â”€ main.py # ğŸš€ Punto de entrada. Lanza la GUI inicial. 

â”œâ”€â”€ perceptron.py # ğŸ§  Clase principal del MLP (lÃ³gica de feedforward, backpropagation, ReLU). 

â”œâ”€â”€ gui_controller.py # ğŸ® LÃ³gica de validaciÃ³n de los formularios de la GUI. 

â”œâ”€â”€ gui_functions.py # âš™ï¸ Funciones para los botones (train, feedforward, save_mlp). 

â”œâ”€â”€ utils.py # ğŸ› ï¸ Funciones auxiliares (leer CSV, seleccionar archivos). 

â”‚ â”œâ”€â”€ config/ 
â”‚   â””â”€â”€ config_mlp.json # ğŸ’¾ Ejemplo de una red guardada (pesos y sesgos). 

â”‚ â””â”€â”€ CSV/ 
    â”œâ”€â”€ 2-d_2-class_train.csv # ğŸ“Š Datos de entrenamiento (2D, 2 clases). 
    â”œâ”€â”€ 2-d_2-class_test.csv # ğŸ§ª Datos de prueba (2D, 2 clases). 
    â”œâ”€â”€ 3-d_4-class_train.csv # ğŸ“Š Datos de entrenamiento (3D, 4 clases). 
    â””â”€â”€ 3-d_4-class_test.csv # ğŸ§ª Datos de prueba (3D, 4 clases).
